{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST - TECH Engines â€“ Junior Data Scientist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective is to implement this formula:\n",
    "\n",
    "$$\n",
    "\\mathcal{L}(S,R,U,T,F,G) = \n",
    "\\dfrac{1}{2}||\\mathcal{A} - \\mathcal{S} \\times_{R} R \\times_{U} U \\times_{T} T||^{2} \n",
    "+ \\dfrac{\\lambda_{1}}{2}||X - TG||^{2} \n",
    "+ \\dfrac{\\lambda_{2}}{2}||Y - RF||^{2}\n",
    "+ \\dfrac{\\lambda_{3}}{2}(||\\mathcal{S}||^{2} + ||R||^{2} + ||U||^{2} + ||T||^{2} + ||F||^{2} + ||G||^{2}) \\, .\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function is called the **objective function** and it is the equivalent of the cost function in machine learning: it is used in an optimization algorithm with the objective of filling the entries of $\\mathcal{A}$, which is a sparse 3D array of data. Before going into the detail of the formula let's focus on each variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the variables in the objective function formula $\\mathcal{L}$:\n",
    "\n",
    "- $\\mathcal{A}$  is a **sparse 3D array of dimensions** $\\rm d_1\\!\\times d_2\\times d_3$. This is a **matrix of data**, where a lot of its entries are missing. \n",
    "\n",
    "    **Note:** The final objective for which the function $\\mathcal{L}$ is used is to fill in the entries of $\\mathcal{A}$!\n",
    "\n",
    "\n",
    "- $X$ are $Y$ are **2D arrays**. They are **matrices of data**, which should not be modified by program, and that I think should be **global variables**.\n",
    "    * $X$ has dimensions $\\rm d_3\\times d_X$\n",
    "    * $Y$ has dimensions $\\rm d_1 \\times d_Y$\n",
    "\n",
    "\n",
    "- $R$, $U$, $T$, $F$ and $G$ are **2D arrays**. These matrices are used in the optimization algorithm: they are initialized with small random values and then updated at every iteration to minimize the $\\mathcal{L}$ function.\n",
    "    * $R$ has dimensions $\\rm d_1 \\times d_R$\n",
    "    * $U$ has dimensions $\\rm d_2 \\times d_U$\n",
    "    * $T$ has dimensions $\\rm d_3 \\times d_T$\n",
    "    * $F$ has dimensions $\\rm d_R \\times d_Y$\n",
    "    * $G$ has dimensions $\\rm d_T \\times d_X$\n",
    "\n",
    "\n",
    "- $\\mathcal{S}$ is a **3D array of dimensions** $\\rm d_R \\times d_U \\times d_T$. This is also used in the optimization algorithm and it is updated every iteration to minimize the $\\mathcal{L}$ function.\n",
    "\n",
    "\n",
    "- $\\lambda_1$, $\\lambda_2$ and $\\lambda_3$ are **parameters** of the function, which will have to be tuned during the hyperparameter tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note on Dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dimensions are important as they are correlated!\n",
    "\n",
    "- $d_1$, $d_2$, $d_3$, $d_X$ and $d_Y$ are in general very large, and directly depend on the data.\n",
    "- $d_R$, $d_U$ and $d_T$ are usually small, and are fixed by the program."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoding the Formula"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's look at the formula step by step, and see what each term means:\n",
    " - $||\\cdot ||$ is the square root of the sum of the squared entries.\n",
    "     \n",
    "    In Python this norm can be implemented in the following way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def norm(A):\n",
    "    sum = 0\n",
    "    for a in A.flatten():\n",
    "        sum += a**2\n",
    "    norm = np.sqrt(sum)\n",
    "    return norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   or using the `scipy` function `lingalg.norm()`, which is faster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "from scipy import linalg\n",
    "\n",
    "# Create a 2D array and a 3D array\n",
    "np.random.seed(1)\n",
    "A = np.random.rand(5,7)*10\n",
    "B = np.random.rand(5,7,2)*10\n",
    "\n",
    "# Calculating the norm with linalg.norm()\n",
    "norm_A = linalg.norm(A)\n",
    "norm_B = linalg.norm(B)\n",
    "\n",
    "# Calculating the norm with the norm() function\n",
    "my_norm_A = norm(A)\n",
    "my_norm_B = norm(B)\n",
    "\n",
    "# Check is the norm() function gives the same result as the linalg.norm()\n",
    "print(format(my_norm_A, '1.14f') == format(norm_A, '1.14f'))\n",
    "print(format(my_norm_B, '1.14f') == format(norm_B, '1.14f'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $TG$ and $RF$ are matrix multiplications, which in Python are implemented by the `np.dot()` function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $\\times_R$ denotes a multiplication between a 3D array and a 2D array which results in a new 3D array. The suffixes just denote the direction of the multiplication. \n",
    "I did not find a built-in function in Python that does this, but it might be worth it to keep looking. As I implemented this, I thought that the best thing to do was to calculate the whole term $\\mathcal{S} \\times_{R} R \\times_{U} U \\times_{T} T$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_matrix_dot(T,M1,M2,M3):\n",
    "    \"\"\"\n",
    "    type T: 3D array\n",
    "    type M1: 2D array\n",
    "    type M2: 2D array\n",
    "    type M3: 2D array\n",
    "    rtype: 3D array\n",
    "    NOTE: the order of the matrices is important! It is such that \n",
    "    T.shape[0]=M1.shape[1]\n",
    "    T.shape[1]=M2.shape[1]\n",
    "    T.shape[2]=M3.shape[1]\n",
    "    \"\"\"\n",
    "    # Initialize the 3D array where we store the results\n",
    "    W = np.zeros((M1.shape[0], M2.shape[0], M3.shape[0]))\n",
    "    \n",
    "    # Compute the entries of A\n",
    "    for i in range(M1.shape[0]):\n",
    "        for j in range(M2.shape[0]):\n",
    "            for k in range(M3.shape[0]):\n",
    "                for l in range(M1.shape[1]):\n",
    "                    for m in range(M2.shape[1]):\n",
    "                        for n in range(M3.shape[1]):\n",
    "                            W[i,j,k] += T[l,m,n]*M1[i,l]*M2[j,m]*M3[k,n]\n",
    "    \n",
    "    return W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** This implementation needs improvement. The matrices that are going to be used are very large and the moltitude of for loops will make the computation of this product very costly.\n",
    "\n",
    "The image below shows how this product of a 3D array and 3 2D arrays gives a 3D array:\n",
    "\n",
    "<img src=\"tensor_matrix_dot2.jpg\"  width='300'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of implementation of the function "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putting everything together, here is an example of the implementation of the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import linalg\n",
    "\n",
    "np.random.seed(123)\n",
    "\n",
    "# Create some sample data\n",
    "# A: 3D array d1*d2*d3\n",
    "# X: 2D array d3*dX\n",
    "# Y: 2D array d1*dY\n",
    "A = np.random.rand(15,10,24)*100 # NOTE: in a real-case scenario this is sparse!!\n",
    "X = np.random.rand(24,16)*100\n",
    "Y = np.random.rand(15,8)*100\n",
    "\n",
    "# Dimensions\n",
    "(d1, d2, d3) = A.shape\n",
    "dX = X.shape[1]\n",
    "dY = Y.shape[1]\n",
    "dR, dU, dT = 5, 5, 5\n",
    "\n",
    "# Initialize S, R, U, T, F and G with small random values\n",
    "S = np.random.rand(dR,dU,dT)\n",
    "R = np.random.rand(d1,dR)\n",
    "U = np.random.rand(d2,dU)\n",
    "T = np.random.rand(d3,dT)\n",
    "F = np.random.rand(dR,dY)\n",
    "G = np.random.rand(dT,dX)\n",
    "\n",
    "\n",
    "def L(S, R, U, T, F, G, l1=1, l2=1, l3=1):\n",
    "    \"\"\"\n",
    "    :type S: 3D array dR*dU*dT\n",
    "    :type R: 2D array d1*dR\n",
    "    :type U: 2D array d2*dU\n",
    "    :type T: 2D array d3*dT\n",
    "    :type F: 2D array dR*dY\n",
    "    :type G: 2D array dT*dX\n",
    "    :type l1: float\n",
    "    :type l2: float\n",
    "    :type l3: float\n",
    "    :rtype: float\n",
    "    \"\"\"\n",
    "    # Calculate each term of the formula\n",
    "    normA2 = linalg.norm(A - tensor_matrix_dot(S,R,U,T))**2\n",
    "    normX2 = linalg.norm(X - np.dot(T,G))**2\n",
    "    normY2 = linalg.norm(Y - np.dot(R,F))**2\n",
    "    normS2 = linalg.norm(S)**2\n",
    "    normR2 = linalg.norm(R)**2\n",
    "    normU2 = linalg.norm(U)**2\n",
    "    normT2 = linalg.norm(T)**2\n",
    "    normF2 = linalg.norm(F)**2\n",
    "    normG2 = linalg.norm(G)**2\n",
    "    \n",
    "    # Calculate the result of the formula\n",
    "    result = normA2/2 + l1/2*normX2 + l2/2*normY2 + l3/2*(normS2 + normR2 + normU2+ normT2 + normF2 + normG2)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5537743.681647928"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L(S,R,U,T,F,G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By just using random numbers this number is very big!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bigger Picture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After implementing the function $\\mathcal{L}$, the final objective would be to use it inside an optimization algorithm which updates the values of $\\mathcal{S}$, $R$, $U$, $T$, $F$ and $G$ at every iteration to minimize the output of the function $\\mathcal{L}$. Once this is done, one can use $\\mathcal{S}$, $R$, $U$ and $T$ to fill in the missing entries of $\\mathcal{A}$ like this:\n",
    "$$\n",
    "\\mathcal{A}_{fill} = \\mathcal{S} \\times_{R} R \\times_{U} U \\times_{T} T\n",
    "$$\n",
    "or, using the example of implementation of this product: `tensor_matrix_dot(S,R,U,T)`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Applications and Further Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The applications of this function are varied. As an example, the authors of the [paper](https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/frp0557-zheng1.pdf) we are refferring to use it to estimate the travel time of any path in a city in real time, starting from just a few GPS trajectories of vehicles received in current time (which is their sparce $\\mathcal{A}$ matrix) and a period of history data (which is their $X$) as well as map data sources (which is their $Y$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another good resource is this [paper](https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/frp0557-zheng1.pdf) where they have released the [data and the code](https://www.microsoft.com/en-us/research/publication/travel-time-estimation-of-a-path-using-sparse-trajectories/?from=http%3A%2F%2Fresearch.microsoft.com%2Fapps%2Fpubs%2F%3Fid%3D217493), which might be a good future reference in case we want to develope the optimization algorithm."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
